{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from boardgame import game1, game2, game3, game4, data_augmentation\n",
    "\n",
    "# Choose game Go\n",
    "game = game1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 5 agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "\"\"\"                    TRAINING 5X5 GO AGENT                      \"\"\"\n",
    "#####################################################################\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from boardgame import game1, game2, game3, game4, data_augmentation\n",
    "\n",
    "# Choose game Go\n",
    "game = game1()\n",
    "\n",
    "#####################################################################\n",
    "\"\"\"                    DEFINE HYPERPARAMETERS                     \"\"\"\n",
    "#####################################################################\n",
    "# Initial Learning Rate\n",
    "alpha = 0.001\n",
    "# size of minibatch\n",
    "size_minibatch = 1024\n",
    "# training epoch\n",
    "max_epoch = 10\n",
    "# number of training steps for each generation\n",
    "n_train_list = [3000, 10000, 18000, 25000, 45000]\n",
    "n_test_list = [1000, 1000, 1000, 1000, 1000]\n",
    "\n",
    "#####################################################################\n",
    "\"\"\"                COMPUTATIONAL GRAPH CONSTRUCTION               \"\"\"\n",
    "#####################################################################\n",
    "\n",
    "### DEFINE OPTIMIZER ###\n",
    "def network_optimizer(Y, Y_, alpha, scope):\n",
    "    # Cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y, labels = Y_))\n",
    "    # Parameters in this scope\n",
    "    variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = scope)\n",
    "    # L2 regularization\n",
    "    for i in range(len(variables)):\n",
    "        loss += 0.0001 * tf.nn.l2_loss(variables[i])\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(alpha).minimize(loss,\\\n",
    "            var_list = variables)\n",
    "    return loss, optimizer\n",
    "\n",
    "\n",
    "### NETWORK ARCHITECTURE ###\n",
    "def network(state, nx, ny):\n",
    "    # Set variable initializers\n",
    "    init_weight = tf.random_normal_initializer(stddev = 0.1)\n",
    "    init_bias = tf.constant_initializer(0.1)\n",
    "\n",
    "    # Create variables \"weights1\" and \"biases1\".\n",
    "    weights1 = tf.get_variable(\"weights1\", [3, 3, 3, 30], initializer = init_weight)\n",
    "    biases1 = tf.get_variable(\"biases1\", [30], initializer = init_bias)\n",
    "\n",
    "    # Create 1st layer\n",
    "    conv1 = tf.nn.conv2d(state, weights1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    out1 = tf.nn.relu(conv1 + biases1)\n",
    "\n",
    "    # Create variables \"weights2\" and \"biases2\".\n",
    "    weights2 = tf.get_variable(\"weights2\", [3, 3, 30, 50], initializer = init_weight)\n",
    "    biases2 = tf.get_variable(\"biases2\", [50], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd layer\n",
    "    conv2 = tf.nn.conv2d(out1, weights2, strides = [1, 1, 1, 1], padding ='SAME')\n",
    "    out2 = tf.nn.relu(conv2 + biases2)\n",
    "\n",
    "    # Create variables \"weights3\" and \"biases3\".\n",
    "    weights3 = tf.get_variable(\"weights3\", [3, 3, 50, 70], initializer = init_weight)\n",
    "    biases3 = tf.get_variable(\"biases3\", [70], initializer = init_bias)\n",
    "\n",
    "    # Create 3rd layer\n",
    "    conv3 = tf.nn.conv2d(out2, weights3, strides = [1, 1, 1, 1], padding ='SAME')\n",
    "    out3 = tf.nn.relu(conv3 + biases3)\n",
    "\n",
    "    # Create variables \"weights1fc\" and \"biases1fc\".\n",
    "    weights1fc = tf.get_variable(\"weights1fc\", [nx * ny * 70, 100], initializer = init_weight)\n",
    "    biases1fc = tf.get_variable(\"biases1fc\", [100], initializer = init_bias)\n",
    "\n",
    "    # Create 1st fully connected layer\n",
    "    fc1 = tf.reshape(out3, [-1, nx * ny * 70])\n",
    "    out1fc = tf.nn.relu(tf.matmul(fc1, weights1fc) + biases1fc)\n",
    "\n",
    "    # Create variables \"weights2fc\" and \"biases2fc\".\n",
    "    weights2fc = tf.get_variable(\"weights2fc\", [100, 3], initializer = init_weight)\n",
    "    biases2fc = tf.get_variable(\"biases2fc\", [3], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd fully connected layer\n",
    "    return tf.matmul(out1fc, weights2fc) + biases2fc\n",
    "\n",
    "\n",
    "# Input\n",
    "S = tf.placeholder(tf.float32, shape = [None, game.nx, game.ny, 3], name = \"S\")\n",
    "\n",
    "# Define network\n",
    "scope = \"network\"\n",
    "with tf.variable_scope(scope):\n",
    "    # Estimation for unnormalized log probability\n",
    "    Y = network(S, game.nx, game.ny) \n",
    "    # Estimation for probability\n",
    "    P = tf.nn.softmax(Y, name = \"softmax\")\n",
    "    # Target in integer\n",
    "    W = tf.placeholder(tf.int32, shape = [None], name = \"W\")\n",
    "    # Target in one-hot vector\n",
    "    Y_= tf.one_hot(W, 3, name = \"Y_\")\n",
    "    # Define loss and optimizer for value network\n",
    "    loss, optimizer = network_optimizer(Y, Y_, alpha, scope)\n",
    "\n",
    "### SAVER ###\n",
    "saver = tf.train.Saver(max_to_keep = 0)\n",
    "\n",
    "#####################################################################\n",
    "\"\"\"                 TRAINING AND TESTING NETWORK                  \"\"\"\n",
    "#####################################################################\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ### DEFAULT SESSION ###\n",
    "    sess.as_default()\n",
    "\n",
    "    win1 = []; lose1 = []; tie1 = [];\n",
    "    win2 = []; lose2 = []; tie2 = [];\n",
    " \n",
    "    ### VARIABLE INITIALIZATION ###\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for generation in range(len(n_train_list)):\n",
    "        print(\"Generating training data for generation %d\" % generation)\n",
    "                \n",
    "        if generation == 0:\n",
    "            # number of games to play for training\n",
    "            n_train = n_train_list[generation] \n",
    "            # number of games to play for testing\n",
    "            n_test = n_test_list[generation]\n",
    "            # randomness for all games\n",
    "            r1 = np.ones((n_train)) # randomness for player 1 for all games\n",
    "            r2 = np.ones((n_train)) # randomness for player 2 for all games\n",
    "            [d, w] = game.play_games([], r1, [], r2, n_train, nargout = 2)\n",
    "        else:\n",
    "            # Play 'ng' games between two players using the previous\n",
    "            # generation value network \n",
    "            # introduce randomness in moves for robustness\n",
    "            n_train = n_train_list[generation] # number of games to play for training\n",
    "            n_test = n_test_list[generation]   # number of games to play for testing\n",
    "            mt = game.nx * game.ny // 2\n",
    "            # decrease randomness with generations\n",
    "            r1r = np.random.rand(n_train, 1) / float(np.clip(generation, 0, 4))\n",
    "            r2r = np.random.rand(n_train, 1) / float(np.clip(generation, 0, 4))\n",
    "            r1k = np.random.randint(mt * 2, size = (n_train, 1))\n",
    "            r2k = np.random.randint(mt * 2, size = (n_train, 1))\n",
    "            r1 = (r1k > mt // np.clip(generation, 0, 4)) * r1r + \\\n",
    "                                        (r1k <= mt // np.clip(generation, 0, 4)) * (-r1k)\n",
    "            r2 = (r2k > mt // np.clip(generation, 0, 4)) * r2r + \\\n",
    "                                        (r2k <= mt // np.clip(generation, 0, 4)) * (-r2k)\n",
    "            [d, w] = game.play_games(P, r1, P, r2, n_train, nargout = 2)\n",
    "\n",
    "        # Data augmentation\n",
    "        print(\"Data augmentation\")\n",
    "        [d, w, _] = data_augmentation(d, w, [])\n",
    "        d = np.rollaxis(d, 3)\n",
    "        \n",
    "        iteration = 0\n",
    "        print(\"Start training\")\n",
    "        # Train the next generation value network\n",
    "        for epoch in range(max_epoch):\n",
    "            # random shuffling\n",
    "            data_index = np.arange(len(w))\n",
    "            np.random.shuffle(data_index) \n",
    "            num_batch = np.ceil(len(data_index) / float(size_minibatch))\n",
    "            for batch_index in range(int(num_batch)):\n",
    "                batch_start = batch_index * size_minibatch\n",
    "                batch_end = min((batch_index + 1) * size_minibatch, len(data_index))\n",
    "                indices = data_index[np.arange(batch_start, batch_end)]\n",
    "                feed_dict = {S: d[indices, :, :, :], W: w[indices]}\n",
    "                sess.run(optimizer, feed_dict = feed_dict)\n",
    "                iteration += 1\n",
    "                if iteration % 100 == 99:\n",
    "                    print(\"Epoch: %3d\\t Iteration: %6d\\t Loss: %10.5f\" %\\\n",
    "                        (epoch, iteration, sess.run(loss, feed_dict = feed_dict)))\n",
    "\n",
    "        # Save session.\n",
    "        saver.save(sess, \"./project3_task2_gen\" + str(generation) + \".ckpt\")\n",
    "        # Load session\n",
    "        # saver.restore(sess, \"./go_gen\" + str(generation) + \".ckpt\")\n",
    "\n",
    "        print(\"Evaluating generation %d neural network against random policy\" % generation)\n",
    "    \n",
    "        r1 = np.zeros((n_test)) # randomness for player 1\n",
    "        r2 = np.ones((n_test))  # randomness for player 2\n",
    "        s = game.play_games(P, r1, [], r2, n_test, nargout = 1)\n",
    "        win1.append(s[0][0]); lose1.append(s[0][1]); tie1.append(s[0][2]);\n",
    "        print(\" net plays black: win=%6.4f, loss=%6.4f, tie=%6.4f\" %\\\n",
    "            (win1[generation], lose1[generation], tie1[generation]))\n",
    "    \n",
    "        r1 = np.ones((n_test))  # randomness for player 1\n",
    "        r2 = np.zeros((n_test)) # randomness for player 2\n",
    "        s = game.play_games([], r1, P, r2, n_test, nargout = 1)\n",
    "        win2.append(s[0][1]); lose2.append(s[0][0]); tie2.append(s[0][2]);\n",
    "        print(\" net plays white: win=%6.4f, loss=%6.4f, tie=%6.4f\" %\\\n",
    "            (win2[generation], lose2[generation], tie2[generation]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25 round-robin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NETWORK ARCHITECTURE ###\n",
    "def network(state, nx, ny):\n",
    "    # Set variable initializers\n",
    "    init_weight = tf.random_normal_initializer(stddev = 0.1)\n",
    "    init_bias = tf.constant_initializer(0.1)\n",
    "\n",
    "    # Create variables \"weights1\" and \"biases1\".\n",
    "    weights1 = tf.get_variable(\"weights1\", [3, 3, 3, 30], initializer = init_weight)\n",
    "    biases1 = tf.get_variable(\"biases1\", [30], initializer = init_bias)\n",
    "\n",
    "    # Create 1st layer\n",
    "    conv1 = tf.nn.conv2d(state, weights1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    out1 = tf.nn.relu(conv1 + biases1)\n",
    "\n",
    "    # Create variables \"weights2\" and \"biases2\".\n",
    "    weights2 = tf.get_variable(\"weights2\", [3, 3, 30, 50], initializer = init_weight)\n",
    "    biases2 = tf.get_variable(\"biases2\", [50], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd layer\n",
    "    conv2 = tf.nn.conv2d(out1, weights2, strides = [1, 1, 1, 1], padding ='SAME')\n",
    "    out2 = tf.nn.relu(conv2 + biases2)\n",
    "\n",
    "    # Create variables \"weights3\" and \"biases3\".\n",
    "    weights3 = tf.get_variable(\"weights3\", [3, 3, 50, 70], initializer = init_weight)\n",
    "    biases3 = tf.get_variable(\"biases3\", [70], initializer = init_bias)\n",
    "\n",
    "    # Create 3rd layer\n",
    "    conv3 = tf.nn.conv2d(out2, weights3, strides = [1, 1, 1, 1], padding ='SAME')\n",
    "    out3 = tf.nn.relu(conv3 + biases3)\n",
    "\n",
    "    # Create variables \"weights1fc\" and \"biases1fc\".\n",
    "    weights1fc = tf.get_variable(\"weights1fc\", [nx * ny * 70, 100], initializer = init_weight)\n",
    "    biases1fc = tf.get_variable(\"biases1fc\", [100], initializer = init_bias)\n",
    "\n",
    "    # Create 1st fully connected layer\n",
    "    fc1 = tf.reshape(out3, [-1, nx * ny * 70])\n",
    "    out1fc = tf.nn.relu(tf.matmul(fc1, weights1fc) + biases1fc)\n",
    "\n",
    "    # Create variables \"weights2fc\" and \"biases2fc\".\n",
    "    weights2fc = tf.get_variable(\"weights2fc\", [100, 3], initializer = init_weight)\n",
    "    biases2fc = tf.get_variable(\"biases2fc\", [3], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd fully connected layer\n",
    "    return tf.matmul(out1fc, weights2fc) + biases2fc\n",
    "\n",
    "\n",
    "# Input (common for all networks)\n",
    "S = tf.placeholder(tf.float32, shape = [None, game.nx, game.ny, 3], name = \"S\")\n",
    "\n",
    "# temporary network for loading from .ckpt\n",
    "scope = \"network\"\n",
    "with tf.variable_scope(scope):\n",
    "    # Estimation for unnormalized log probability\n",
    "    Y = network(S, game.nx, game.ny) \n",
    "    # Estimation for probability\n",
    "    P = tf.nn.softmax(Y, name = \"softmax\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# network0 for black\n",
    "# network1 for white\n",
    "for i in range(5):\n",
    "    scope = \"network\" + str(i)\n",
    "    with tf.variable_scope(scope):\n",
    "        # Estimation for unnormalized log probability\n",
    "        Y = network(S, game.nx, game.ny) \n",
    "        # Estimation for probability\n",
    "        P = tf.nn.softmax(Y, name = \"softmax\")\n",
    "\n",
    "N_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network/\")\n",
    "N0_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network0/\")\n",
    "N1_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network1/\")\n",
    "N2_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network2/\")\n",
    "N3_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network3/\")\n",
    "N4_variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = \"network4/\")\n",
    "nets_vars = [N0_variables,N1_variables,N2_variables,N3_variables,N4_variables]\n",
    "### SAVER ###\n",
    "saver = tf.train.Saver(N_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./project3_task2_gen0.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./project3_task2_gen1.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./project3_task2_gen2.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./project3_task2_gen3.ckpt\n",
      "INFO:tensorflow:Restoring parameters from ./project3_task2_gen4.ckpt\n",
      "net1 (black) against net1 (white): win 1, loss 0, tie 0\n",
      "net1 (black) against net2 (white): win 0, loss 1, tie 0\n",
      "net1 (black) against net3 (white): win 0, loss 1, tie 0\n",
      "net1 (black) against net4 (white): win 0, loss 1, tie 0\n",
      "net1 (black) against net5 (white): win 0, loss 1, tie 0\n",
      "net2 (black) against net1 (white): win 1, loss 0, tie 0\n",
      "net2 (black) against net2 (white): win 1, loss 0, tie 0\n",
      "net2 (black) against net3 (white): win 0, loss 0, tie 1\n",
      "net2 (black) against net4 (white): win 0, loss 1, tie 0\n",
      "net2 (black) against net5 (white): win 0, loss 1, tie 0\n",
      "net3 (black) against net1 (white): win 1, loss 0, tie 0\n",
      "net3 (black) against net2 (white): win 1, loss 0, tie 0\n",
      "net3 (black) against net3 (white): win 0, loss 1, tie 0\n",
      "net3 (black) against net4 (white): win 0, loss 0, tie 1\n",
      "net3 (black) against net5 (white): win 0, loss 1, tie 0\n",
      "net4 (black) against net1 (white): win 1, loss 0, tie 0\n",
      "net4 (black) against net2 (white): win 1, loss 0, tie 0\n",
      "net4 (black) against net3 (white): win 1, loss 0, tie 0\n",
      "net4 (black) against net4 (white): win 1, loss 0, tie 0\n",
      "net4 (black) against net5 (white): win 1, loss 0, tie 0\n",
      "net5 (black) against net1 (white): win 1, loss 0, tie 0\n",
      "net5 (black) against net2 (white): win 1, loss 0, tie 0\n",
      "net5 (black) against net3 (white): win 1, loss 0, tie 0\n",
      "net5 (black) against net4 (white): win 1, loss 0, tie 0\n",
      "net5 (black) against net5 (white): win 1, loss 0, tie 0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    ### DEFAULT SESSION ###\n",
    "    sess.as_default()\n",
    "\n",
    "    ### VARIABLE INITIALIZATION ###\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    n_test = 1\n",
    "    r_none = np.zeros((n_test))\n",
    "    nets = []\n",
    "    for n in range(len(nets_vars)):\n",
    "        saver.restore(sess, \"./project3_task2_gen%d.ckpt\"%(n))\n",
    "        for i in range(len(N_variables)):\n",
    "            sess.run(tf.assign(nets_vars[n][i], N_variables[i]))\n",
    "        nets += [tf.get_default_graph().get_tensor_by_name(\"network%d/softmax:0\"%(n))]\n",
    "\n",
    "    for i in range(len(nets)):\n",
    "        for j in range(len(nets)):\n",
    "            s = game.play_games(nets[i], r_none, nets[j], r_none, n_test, nargout = 1)\n",
    "            win=s[0][0]; loss=s[0][1]; tie=s[0][2]\n",
    "            print('net%d (black) against net%d (white): win %d, loss %d, tie %d' % \\\n",
    "                                                              (i+1, j+1, win, loss, tie))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanations\n",
    "\n",
    "For training the following settings were used:\n",
    "1. n_train_list = [3000, 10000, 18000, 25000, 45000]\n",
    "2. n_test_list = [1000, 1000, 1000, 1000, 1000]\n",
    "3. Exploration was decreasing proportionaly to the generation number,as shown in the code below\n",
    "\n",
    "From the 25 round-robin results above it can be seen that:\n",
    "1. Black player has a tendecy to win more frequently than the white player:\n",
    "        * whenever the agent with the same parameters and from the same generation plays against itself, the white player always looses\n",
    "2. With more generations the agent becomes more powerful, because it sees more games and the value function becomes more accurate. In this simplified setting only the value function is used without the Monte Carlo Tree Search for policy optimization, hence there is no policy evaluation and improvement loop, and the single loss signal is coming at the end of the game. \n",
    "\n",
    "3. Due to simplifiaction in the agent network explained above and simple exploration policy (without visit count), the agent from 5th generation white agent looses against the 4th generation black agent; as well as 4th generation white agent could not beat the 3rd generation black agent. Therefore in order to make the agent more effective the algorithm has to be improved itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

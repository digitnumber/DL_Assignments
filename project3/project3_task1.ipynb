{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from boardgame import game1, game2, game3, game4, data_augmentation\n",
    "\n",
    "restore = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified environment for the Tic-tac-toe\n",
    "In order to prove that the agent can solve any game with all behaviours, wins agains the random player are not the sufficient conditions, since it gives only the probabilistic conclusion.\n",
    "Therefore, the functions **next_move_all** and **play_games_all** were defined, which are implementing the following:\n",
    "\n",
    "1. During every move of the random player the amount of boards is expanded by $n_{xy}=3 \\times 3 = 9$ times. It is due to the policy of exploring every possible move on the board, which is clearly less or equal to number of cells.\n",
    "2. In order to keep track of boards that where unfinished, or in other words, where random player made an invalid move to the cell which was already occupied, an array **finished_games** is used, that stores markers for all games among $9^5$ if the random player is black (or $9^4$ if it is white) that were finished properly: win, loss or tie.\n",
    "3. For example, for _black_ random player (similar strategy is helf for _white_ random player) the boards look: \n",
    "\n",
    "    * move = 1: np.repeat([$1, 2, 3, ..., 9$], $9^4$), where $i$ represents the board where stone is on [$i \\div 3, i \\mod 3$] for [$3\\times 3$] board\n",
    "    * move = 2: np.repeat([$1b_1, 2b_2, 3b_3, ..., 9b_9$], $9^4$), where $ib_j$ represents the board where the agent put a stone is on [$b_j \\div 3, b_j \\mod 3$] and  the random player stone on [$i \\div 3, i \\mod 3$]\n",
    "    * move = 3: np.repeat([$1b_11, 1b_12, ..., 1b_19, 2b_21, ..., 2b_29, ..., 9b_99$], $9^3$), where $ib_jk$ represents the board with the stones on [$i \\div 3, i\\mod3$], [$b_j \\div 3, b_j \\mod 3$], and [$j\\div 3, j\\mod 3$]\n",
    "    * etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class my_game2(game2):\n",
    "   \n",
    "    def next_move_all(self, b, state, game_in_progress, net, rn, p, move,\\\n",
    "                                          finished_games, nlevels = 1, rw = 0):\n",
    "        # returns next move by using neural networks\n",
    "        # this is a parallel version, i.e., returns next moves for multiple games\n",
    "        # Input arguments: self,b,state,game_in_progress,net,rn,p,move,nlevels,rw\n",
    "        # self: game parameters\n",
    "        # b: current board status for multiple games\n",
    "        # state: extra state for the board\n",
    "        # game_in_progress: 1 if game is in progress, 0 if ended\n",
    "        # net: neural network. can be empty (in that case 'rn' should be 1)\n",
    "        # rn: randomness in the move, 0: no randomness, 1: pure random\n",
    "        #   if rn<0, then the first |rn| moves are random\n",
    "        # p: current player (1: black, 2: white)\n",
    "        # move: k-th move (1,2,3,...)\n",
    "        # nlevels (optional): tree search depth (1,2, or 3). default=1\n",
    "        #   if nlevels is even, then 'net' should be the opponent's neural network\n",
    "        # rw (optional): randomization in calculating winning probabilities, default=0\n",
    "        # Return values\n",
    "        # new_board,new_state,valid_moves,wp_max,wp_all,x,y=next_move(b,\n",
    "        #                                             game_in_progress,net,rn,p,move)\n",
    "        #   new_board: updated boards containing new moves\n",
    "        #   new_state: update states\n",
    "        #   n_valid_moves: number of valid moves\n",
    "        #   wp_max: best likelihood of winning\n",
    "        #   wp_all: likelihood of winning for all possible next moves\n",
    "        #   x: x coordinates of next moves\n",
    "        #   y: y coordinates of next moves\n",
    "        \n",
    "        # board size\n",
    "        nx = self.nx; ny = self.ny; nxy = nx * ny\n",
    "        # randomness for each game & minimum r\n",
    "        r = rn; rmin = np.amin(r)\n",
    "        ng_original = b.shape[2]\n",
    "        # number of games\n",
    "        if move % 2 ==0:\n",
    "            if rmin == 1:\n",
    "                ng = b.shape[2] / pow(nxy, (nxy-move)//2)\n",
    "            else:\n",
    "                ng = b.shape[2] / pow(nxy, (nxy-1-move)//2)\n",
    "        else:\n",
    "            if rmin == 0:\n",
    "                ng = b.shape[2] / pow(nxy, (nxy-move)//2)\n",
    "            else:\n",
    "                ng = b.shape[2] / pow(nxy, (nxy-1-move)//2)\n",
    "    \n",
    "        # proper number of different games for the current move   \n",
    "        # slicing with appropriate stepsize     \n",
    "        r = r[::(ng_original/ng)] \n",
    "        game_in_progress = game_in_progress[::(ng_original/ng)] \n",
    "        b = b[:,:,::(ng_original/ng)] \n",
    "        state = state[:,::(ng_original/ng)] \n",
    "        finished_games = finished_games[::(ng_original/ng)]\n",
    "\n",
    "        # number of valid moves in each game \n",
    "        n_valid_moves = np.zeros((ng))\n",
    "        # check whether moves ('nxy' moves) are valid\n",
    "        valid_moves = np.zeros((ng, nxy))\n",
    "        # win probability for each position on this each game\n",
    "        wp_all = np.zeros((nx, ny, ng))\n",
    "        # maximum over wp_all\n",
    "        wp_max = -np.ones((ng))\n",
    "        mx = np.zeros((ng))\n",
    "        my = np.zeros((ng))\n",
    "        x = -np.ones((ng))\n",
    "        y = -np.ones((ng))\n",
    "\n",
    "        # check nlevels\n",
    "        if nlevels > 3 or nlevels <= 0:\n",
    "            raise Exception('# of levels not supported. Should be 1, 2, or 3.')\n",
    "        # total cases to consider in tree search\n",
    "        ncases = pow(nxy, nlevels)\n",
    "\n",
    "        # All possible boards after 'b'\n",
    "        d = np.zeros((nx, ny, 3, ng * ncases), dtype = np.int32)\n",
    "\n",
    "        for p1 in range(nxy):\n",
    "            if rmin == 1:\n",
    "                b_prev_games = b[:,:,::nxy]\n",
    "                vm1, b1, state1 = self.valid(b_prev_games, state, self.xy(p1), p)\n",
    "                vm_dilute = np.zeros((ng))\n",
    "                vm_dilute[::nxy] = vm1\n",
    "                vm_dilute = np.roll(vm_dilute, p1)\n",
    "                n_valid_moves += vm_dilute\n",
    "                assert np.amax(n_valid_moves) == 1\n",
    "\n",
    "            elif rmin < 1:\n",
    "                vm1, b1, state1 = self.valid(b, state, self.xy(p1), p)\n",
    "                n_valid_moves += vm1\n",
    "                valid_moves[:, p1] = vm1\n",
    "                if nlevels == 1:\n",
    "                    c = 3 - p       # current player is changed to the next player \n",
    "                    idx = np.arange(ng) + p1 * ng\n",
    "                    d[:, :, 0, idx] = (b1 == c)   # current player's stone\n",
    "                    d[:, :, 1, idx] = (b1 == 3 - c)  # opponent's stone\n",
    "                    d[:, :, 2, idx] = 2 - c # 1: current player is black, 0: white\n",
    "                else:\n",
    "                    for p2 in range(nxy):\n",
    "                        vm2, b2, state2 = self.valid(b1, state1, self.xy(p2), 3 - p)\n",
    "                        if nlevels == 2:\n",
    "                            c = p                 # current player is changed again\n",
    "                            idx = np.arange((ng)) + p1 * ng + p2 * ng * nxy\n",
    "                            d[:, :, 0, idx] = (b2 == c)\n",
    "                            d[:, :, 1, idx] = (b2 == 3 - c)\n",
    "                            d[:, :, 2, idx] = 2 - c\n",
    "                        else:\n",
    "                            for p3 in range(nxy):\n",
    "                                vm3, b3, state3 = self.valid(b2, state2, self.xy(p3), p)\n",
    "                                c = 3 - p         # current player is changed again\n",
    "                                idx = np.arange(ng) + p1 * ng + p2 * ng * nxy\\\n",
    "                                        + p3 * ng * nxy * nxy\n",
    "                                d[:, :, 0, idx] = (b3 == c)\n",
    "                                d[:, :, 1, idx] = (b3 == 3 - c)\n",
    "                                d[:, :, 2, idx] = 2 - c\n",
    "\n",
    "        if rmin == 1:\n",
    "            # for the random player unvalid moves are all that put \n",
    "            # the stone on the occupied cell\n",
    "            finished_games *= n_valid_moves                             \n",
    "        n_valid_moves = n_valid_moves * game_in_progress\n",
    "\n",
    "        # For operations in TensorFlow, load session and graph\n",
    "        sess = tf.get_default_session()\n",
    "\n",
    "        # Axis rollaxis for placeholder inputs\n",
    "        d = np.rollaxis(d, 3)\n",
    "        if rmin < 1: # if not fully random\n",
    "            softout = np.zeros((d.shape[0], 3))\n",
    "            size_minibatch = d.shape[0]//5 + 1\n",
    "            num_batch = np.ceil(d.shape[0] / float(size_minibatch))\n",
    "            for batch_index in range(int(num_batch)):\n",
    "                batch_start = batch_index * size_minibatch\n",
    "                batch_end = \\\n",
    "                        min((batch_index + 1) * size_minibatch, d.shape[0])\n",
    "                indices = range(batch_start, batch_end)\n",
    "                feed_dict = {'S:0': d[indices, :, :, :]}\n",
    "                softout[indices, :] = sess.run(net, feed_dict = feed_dict)\n",
    "            if p == 1:\n",
    "                wp = 0.5 * (1 + softout[:, 1] - softout[:, 2])\n",
    "            else:\n",
    "                wp = 0.5 * (1 + softout[:, 2] - softout[:, 1])\n",
    "\n",
    "            if rw != 0:\n",
    "                wp = wp + np.random.rand((ng, 1)) * rw\n",
    "\n",
    "            if nlevels >= 3:\n",
    "                wp = np.reshape(wp, (ng, nxy, nxy, nxy))\n",
    "                wp = np.amax(wp, axis = 3)\n",
    "\n",
    "            if nlevels >= 2:\n",
    "                wp = np.reshape(wp, (ng, nxy, nxy))\n",
    "                wp = np.amin(wp, axis = 2)\n",
    "\n",
    "            wp = np.transpose(np.reshape(wp,(nxy,ng)))\n",
    "            wp = valid_moves * wp - (1 - valid_moves)\n",
    "            wp_i = np.argmax(wp, axis = 1)\n",
    "            mxy = self.xy(wp_i) # max position\n",
    "\n",
    "            for p1 in range(nxy):\n",
    "                pxy = self.xy(p1)\n",
    "                wp_all[int(pxy[:, 0]), int(pxy[:, 1]), :] = wp[:, p1]\n",
    "\n",
    "        new_board = np.zeros(b.shape)\n",
    "        new_board[:, :, :] = b[:, :, :]\n",
    "        new_state = np.zeros(state.shape)\n",
    "        new_state[:, :] = state[:, :]\n",
    "\n",
    "        for k in range(ng):\n",
    "            if n_valid_moves[k]: # if there are valid moves\n",
    "                if (rmin == 1):\n",
    "                    # if random agent do all possible actions\n",
    "                    # k = v*nxy + j, make jth move always same for each \n",
    "                    # block in [0,1,...,nxy-1]\n",
    "                    rxy = self.xy(k % nxy) \n",
    "                    isvalid, bn, sn = self.valid(b[:, :, [k]], state[:, [k]], rxy, p)\n",
    "                    if int(isvalid[0]):\n",
    "                        #print(k//ng_prev,bn)\n",
    "                        new_board[:, :, [k]] = bn\n",
    "                        new_state[:, [k]] = sn\n",
    "                        x[k] = rxy[0, 0]\n",
    "                        y[k] = rxy[0, 1]\n",
    "\n",
    "                else:    # act according to the value network\n",
    "                    isvalid, bn, sn = self.valid(b[:, :, [k]], state[:, [k]], \\\n",
    "                                                                     mxy[[k], :], p)\n",
    "                    new_board[:, :, [k]] = bn\n",
    "                    new_state[:, [k]] = sn\n",
    "                    x[k] = mxy[k, 0]\n",
    "                    y[k] = mxy[k, 1]\n",
    "\n",
    "            else: # if there is no valid moves\n",
    "                isvalid, bn, sn = self.valid(b[:, :, [k]], state[:, [k]], \\\n",
    "                                                             -np.ones((1, 2)), p)\n",
    "                new_state[:, [k]] = sn\n",
    "\n",
    "        c = ng_original/ng\n",
    "        return np.repeat(new_board,c, axis=2), new_state, \\\n",
    "                np.repeat(n_valid_moves, c, axis=0), np.repeat(wp_max,c,axis=0),\\\n",
    "                np.repeat(wp_all,c,axis=2), x, y, np.repeat(finished_games,c,axis=0)\n",
    "\n",
    "\n",
    "    def play_games_all(self, net1, r1, net2, r2, ng, max_time = 0, nargout = 1):\n",
    "        # plays 'ng' games between two players\n",
    "        # optional parameter: max_time (the number of moves per game), nargout (the number of output of play_games)\n",
    "        # returns dataset and labels\n",
    "        # Inputs\n",
    "        # self: game parameters\n",
    "        # net1: neural network playing black. can be empty (r1 should be 1 if this is empty)\n",
    "        # r1: randomness in the move, 0: no randomness, 1: pure random\n",
    "        #   if r1<0, then the first |r1| moves are random\n",
    "        # net2: neural network playing white. can be empty (r2 should be 1 if this is empty)\n",
    "        # r2: randomness in the move, 0: no randomness, 1: pure random\n",
    "        #   if r2<0, then the first |r2| moves are random\n",
    "        # ng: number of games to play\n",
    "        # Return values\n",
    "        #   stat=play_games(net1,r1,net2,r2,ng,nargout=1): statistics for net1, stat=[win loss tie]\n",
    "        #   d,w,wp,stat=play_games(net1,r1,net2,r2,ng,nargout=2,3, or 4)\n",
    "        #     d: 4-d matrix of size nx*ny*3*nb containing all moves, where nb is the total number of board configurations\n",
    "        #     w: nb*1, 0: tie, 1: black wins, 2: white wins\n",
    "        #     wp (if nargout>=3):  win probabilities for the current player\n",
    "        #     stat (if nargout==4): statistics for net1, stat=[win loss tie], for net2, swap win & loss\n",
    "        \n",
    "        \n",
    "        # board size \n",
    "        nx = self.nx; ny = self.ny\n",
    "        assert np.amin(r1) == 1 or np.amin(r2) == 1, \"check randomness coefficients\"\n",
    "        # maximum trials for each game\n",
    "        if np.amin(r1) == 1:\n",
    "            ng = pow(nx*ny, 5)\n",
    "        elif np.amin(r2) == 1:\n",
    "            ng = pow(nx*ny, 4)\n",
    "\n",
    "        if max_time <= 0:\n",
    "            np0 = nx * ny \n",
    "        else:\n",
    "            np0 = max_time\n",
    "\n",
    "        # 'm' possible board configurations\n",
    "        m = np0 * ng\n",
    "        d = np.zeros((nx, ny, 3, m))\n",
    "        pos = np.zeros((nx,ny,m))\n",
    "        \n",
    "        # Check whether tie(0)/black win(1)/white win(2) in all board configurations\n",
    "        w = np.zeros((m))\n",
    "\n",
    "        # winning probability: (no work for 1st generation)       \n",
    "        wp = np.zeros((m))\n",
    "\n",
    "        # Check whether the configurations are valid for training\n",
    "        valid_data = np.zeros((m))\n",
    "\n",
    "        # keep track of games which contain games where random player made a move \n",
    "        # overlapping with existing ones\n",
    "        # == 0 if the game was unfinished due to invalid move from a random player\n",
    "        # == 1 if have not been looked at yet; or eventually was finished\n",
    "        finished_games = np.ones((ng))\n",
    "\n",
    "        vm0 = np.ones((ng))\n",
    "\n",
    "        if hasattr(self, 'game_init'): \n",
    "            [b, state] = self.game_init(ng)\n",
    "        else:\n",
    "            b = np.zeros((nx, ny, ng))\n",
    "            state = np.zeros((0, ng))\n",
    "\n",
    "        # maximum winning probability for each game\n",
    "        wp_max = np.zeros((ng))\n",
    "\n",
    "        # For each time step, check whether game is in progress or not.\n",
    "        game_in_progress = np.ones((ng))\n",
    "\n",
    "        # First player: player 1 (black)\n",
    "        p = 1\n",
    "        for k in range(np0):\n",
    "            if p == 1:\n",
    "                b, state, n_valid_moves, wp_max, _, x_pos, y_pos, finished_games=\\\n",
    "                    self.next_move_all(b, state, game_in_progress, net1, \\\n",
    "                                               r1, p, k, finished_games)\n",
    "            else:\n",
    "                b, state, n_valid_moves, wp_max, _, x_pos, y_pos, finished_games=\\\n",
    "                    self.next_move_all(b, state, game_in_progress, net2,\\\n",
    "                                                r2, p, k, finished_games)\n",
    "\n",
    "            w0, end_game, _, _ = self.winner(b, state)\n",
    "\n",
    "            idx = np.arange(k * ng, (k + 1) * ng)\n",
    "            c = 3 - p    # current player is now changed to the next player\n",
    "            d[:, :, 0, idx] = (b == c)\n",
    "            d[:, :, 1, idx] = (b == 3 - c)\n",
    "            d[:, :, 2, idx] = 2 - c\n",
    "            \n",
    "            wp[idx] = wp_max\n",
    "            valid_data[idx] = game_in_progress * (n_valid_moves > 0)\n",
    "            \n",
    "            # information about who's the current player\n",
    "            game_in_progress *= (n_valid_moves > 0) * (end_game == 0) \n",
    "\n",
    "            # if end_game==1, game ends\n",
    "            # if end_game==0, game ends if no more move is possible for the current player\n",
    "\n",
    "            number_of_games_in_progress = np.sum(game_in_progress)\n",
    "            if number_of_games_in_progress == 0:\n",
    "                break\n",
    "\n",
    "            p = 3 - p\n",
    "            vm0 = n_valid_moves[:]\n",
    "\n",
    "        for k in range(np0):\n",
    "            idx = np.arange(k * ng, (k + 1) * ng)\n",
    "            w[idx] = w0[:] # final winner\n",
    "\n",
    "        # player 1's stat\n",
    "        valid_ng = np.sum(finished_games)\n",
    "        print(\"valid games = %d\" % valid_ng)\n",
    "        win = np.sum(w0*(finished_games) == 1) / float(valid_ng)\n",
    "        loss = np.sum(w0*(finished_games) == 2) / float(valid_ng)\n",
    "        tie = np.sum((w0== 0)*finished_games) / float(valid_ng)\n",
    "\n",
    "        varargout = []\n",
    "\n",
    "        if nargout >= 2:\n",
    "            fv = np.where(valid_data)[0]\n",
    "            varargout.append(d[:, :, :, fv])\n",
    "            varargout.append(w[fv])\n",
    "            if nargout >= 3:\n",
    "                varargout.append(wp[fv])\n",
    "            if nargout >= 4:\n",
    "                varargout.append([win, loss, tie])\n",
    "        else:\n",
    "            varargout.append([win, loss, tie])\n",
    "        return varargout\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose game tic-tac-toe\n",
    "game = my_game2()\n",
    "\n",
    "#####################################################################\n",
    "\"\"\"                    DEFINE HYPERPARAMETERS                     \"\"\"\n",
    "#####################################################################\n",
    "# Initial Learning Rate\n",
    "alpha = 0.001\n",
    "# size of minibatch\n",
    "size_minibatch = 1024\n",
    "# training epoch\n",
    "max_epoch = 10\n",
    "# number of training steps for each generation\n",
    "n_train_list = [5000, 25000, 35000, 45000]\n",
    "n_test_list = [1000, 1000, 1000, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "\"\"\"                COMPUTATIONAL GRAPH CONSTRUCTION               \"\"\"\n",
    "#####################################################################\n",
    "\n",
    "### DEFINE OPTIMIZER ###\n",
    "def network_optimizer(Y, Y_, alpha, scope):\n",
    "    # Cross entropy loss\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y, labels = Y_))\n",
    "    # Parameters in this scope\n",
    "    variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope = scope)\n",
    "    # L2 regularization\n",
    "    for i in range(len(variables)):\n",
    "        loss += 0.0001 * tf.nn.l2_loss(variables[i])\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(alpha).minimize(loss,\\\n",
    "            var_list = variables)\n",
    "    return loss, optimizer\n",
    "\n",
    "\n",
    "### NETWORK ARCHITECTURE ###\n",
    "def network(state, nx, ny):\n",
    "    # Set variable initializers\n",
    "    init_weight = tf.random_normal_initializer(stddev = 0.1)\n",
    "    init_bias = tf.constant_initializer(0.1)\n",
    "\n",
    "    # Create variables \"weights1\" and \"biases1\".\n",
    "    weights1 = tf.get_variable(\"weights1\", [3, 3, 3, 30], initializer = init_weight)\n",
    "    biases1 = tf.get_variable(\"biases1\", [30], initializer = init_bias)\n",
    "\n",
    "    # Create 1st layer\n",
    "    conv1 = tf.nn.conv2d(state, weights1, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "    out1 = tf.nn.relu(conv1 + biases1)\n",
    "\n",
    "    # Create variables \"weights2\" and \"biases2\".\n",
    "    weights2 = tf.get_variable(\"weights2\", [3, 3, 30, 50], initializer = init_weight)\n",
    "    biases2 = tf.get_variable(\"biases2\", [50], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd layer\n",
    "    conv2 = tf.nn.conv2d(out1, weights2, strides = [1, 1, 1, 1], padding ='SAME')\n",
    "    out2 = tf.nn.relu(conv2 + biases2)\n",
    "   \n",
    "    # Create variables \"weights1fc\" and \"biases1fc\".\n",
    "    weights1fc = tf.get_variable(\"weights1fc\", [nx * ny * 50, 100], \\\n",
    "                                                 initializer = init_weight)\n",
    "    biases1fc = tf.get_variable(\"biases1fc\", [100], initializer = init_bias)\n",
    "    \n",
    "    # Create 1st fully connected layer\n",
    "    fc1 = tf.reshape(out2, [-1, nx * ny * 50])\n",
    "    out1fc = tf.nn.relu(tf.matmul(fc1, weights1fc) + biases1fc)\n",
    "\n",
    "    # Create variables \"weights2fc\" and \"biases2fc\".\n",
    "    weights2fc = tf.get_variable(\"weights2fc\", [100, 3], initializer = init_weight)\n",
    "    biases2fc = tf.get_variable(\"biases2fc\", [3], initializer = init_bias)\n",
    "\n",
    "    # Create 2nd fully connected layer\n",
    "    return tf.matmul(out1fc, weights2fc) + biases2fc\n",
    "\n",
    "\n",
    "# Input\n",
    "S = tf.placeholder(tf.float32, shape = [None, game.nx, game.ny, 3], name = \"S\")\n",
    "\n",
    "# Define network\n",
    "scope = \"network\"\n",
    "with tf.variable_scope(scope):\n",
    "    # Estimation for unnormalized log probability\n",
    "    Y = network(S, game.nx, game.ny) \n",
    "    # Estimation for probability\n",
    "    P = tf.nn.softmax(Y, name = \"softmax\")\n",
    "    # Target in integer\n",
    "    W = tf.placeholder(tf.int32, shape = [None], name = \"W\")\n",
    "    # Target in one-hot vector\n",
    "    Y_= tf.one_hot(W, 3, name = \"Y_\")\n",
    "    # Define loss and optimizer for value network\n",
    "    loss, optimizer = network_optimizer(Y, Y_, alpha, scope)\n",
    "\n",
    "### SAVER ###\n",
    "saver = tf.train.Saver(max_to_keep = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./project3_task1_gen3.ckpt\n",
      "Evaluating generation 3 neural network against random policy\n",
      " net plays black: win=0.987000, loss=0.000000, tie=0.013000\n",
      " net plays white: win=0.909000, loss=0.000000, tie=0.091000\n",
      "Evaluating generation 3 neural network against itself\n",
      "win=0.000000, loss=0.000000, tie=1.000000\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "Evaluating generation 3 neural network on all games\n",
      "valid games = 688\n",
      " net plays black: win=0.994186, loss=0.000000, tie=0.005814\n",
      "valid games = 2373\n",
      " net plays white: win=0.963338, loss=0.000000, tie=0.036662\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "\"\"\"                 TRAINING AND TESTING NETWORK                  \"\"\"\n",
    "#####################################################################\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    ### DEFAULT SESSION ###\n",
    "    sess.as_default()\n",
    "\n",
    "    win1 = []; lose1 = []; tie1 = [];\n",
    "    win2 = []; lose2 = []; tie2 = [];\n",
    " \n",
    "    ### VARIABLE INITIALIZATION ###\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    if not restore:\n",
    "        for generation in range(len(n_train_list)):\n",
    "            print(\"Generating training data for generation %d\" % generation)                \n",
    "            if generation == 0:\n",
    "                # number of games to play for training\n",
    "                n_train = n_train_list[generation] \n",
    "                # number of games to play for testing\n",
    "                n_test = n_test_list[generation]\n",
    "                # randomness for all games\n",
    "                r1 = np.ones((n_train)) # randomness for player 1 for all games\n",
    "                r2 = np.ones((n_train)) # randomness for player 2 for all games\n",
    "                [d, w] = game.play_games([], r1, [], r2, n_train, nargout = 2)\n",
    "            elif generation >= 1:\n",
    "                # Play 'ng' games between two players using the previous\n",
    "                # generation value network \n",
    "                # introduce randomness in moves for robustness\n",
    "                n_train = n_train_list[generation] # number of games to play for training\n",
    "                n_test = n_test_list[generation]   # number of games to play for testing\n",
    "                mt = game.nx * game.ny // 2\n",
    "                r1r = np.random.rand(n_train, 1) / float(generation)\n",
    "                r2r = np.random.rand(n_train, 1) / float(generation)\n",
    "                r1k = np.random.randint(mt * 2, size = (n_train, 1))\n",
    "                r2k = np.random.randint(mt * 2, size = (n_train, 1))\n",
    "                r1 = (r1k > mt // generation) * r1r + \\\n",
    "                                            (r1k <= mt // generation) * (-r1k)\n",
    "                r2 = (r2k > mt // generation) * r2r + \\\n",
    "                                            (r2k <= mt // generation) * (-r2k)\n",
    "                [d, w] = game.play_games(P, r1, P, r2, n_train, nargout = 2)\n",
    "\n",
    "            # Data augmentation\n",
    "            print(\"Data augmentation\")\n",
    "            [d, w, _] = data_augmentation(d, w, [])\n",
    "            d = np.rollaxis(d, 3)\n",
    "            \n",
    "            iteration = 0\n",
    "            print(\"Start training\")\n",
    "            # Train the next generation value network\n",
    "            for epoch in range(max_epoch):\n",
    "                # random shuffling\n",
    "                data_index = np.arange(len(w))\n",
    "                np.random.shuffle(data_index) \n",
    "                num_batch = int(np.ceil(len(data_index) / float(size_minibatch)))\n",
    "                for batch_index in range(int(num_batch)):\n",
    "                    batch_start = batch_index * size_minibatch\n",
    "                    batch_end = min((batch_index + 1) * size_minibatch, len(data_index))\n",
    "                    indices = data_index[np.arange(batch_start, batch_end)]\n",
    "                    feed_dict = {S: d[indices, :, :, :], W: w[indices]}\n",
    "                    sess.run(optimizer, feed_dict = feed_dict)\n",
    "                    iteration += 1\n",
    "                    if iteration % 100 == 99:\n",
    "                        print(\"Epoch: %3d\\t Iteration: %6d\\t Loss: %10.5f\" %\\\n",
    "                            (epoch, iteration, sess.run(loss, feed_dict = feed_dict)))\n",
    "\n",
    "            # Save session.\n",
    "            saver.save(sess, \"./project3_task1_gen\" + str(generation) + \".ckpt\")\n",
    "            # Load session\n",
    "            # saver.restore(sess, \"./tictactoe_gen\" + str(generation) + \".ckpt\")\n",
    "\n",
    "            print(\"Evaluating generation %d neural network against random policy\" % generation)\n",
    "        \n",
    "            r1 = np.zeros((n_test)) # randomness for player 1\n",
    "            r2 = np.ones((n_test))  # randomness for player 2\n",
    "            s = game.play_games(P, r1, [], r2, n_test, nargout = 1)\n",
    "            win1.append(s[0][0]); lose1.append(s[0][1]); tie1.append(s[0][2]);\n",
    "            print(\" net plays black: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "                (win1[generation], lose1[generation], tie1[generation]))\n",
    "        \n",
    "            r1 = np.ones((n_test))  # randomness for player 1\n",
    "            r2 = np.zeros((n_test)) # randomness for player 2\n",
    "            s = game.play_games([], r1, P, r2, n_test, nargout = 1)\n",
    "            win2.append(s[0][1]); lose2.append(s[0][0]); tie2.append(s[0][2]);\n",
    "            print(\" net plays white: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "                (win2[generation], lose2[generation], tie2[generation]))\n",
    "\n",
    "    else:\n",
    "        generation = len(n_train_list)-1\n",
    "        n_test = n_test_list[generation]\n",
    "        saver.restore(sess, \"./project3_task1_gen\" + str(generation) + \".ckpt\")\n",
    "        print(\"Evaluating generation %d neural network against random policy\" % generation)\n",
    "    \n",
    "        r1 = np.zeros((n_test)) # randomness for player 1\n",
    "        r2 = np.ones((n_test))  # randomness for player 2\n",
    "        s = game.play_games(P, r1, [], r2, n_test, nargout = 1)\n",
    "        print(\" net plays black: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "            (s[0][0],s[0][1],s[0][2]))\n",
    "    \n",
    "        r1 = np.ones((n_test))  # randomness for player 1\n",
    "        r2 = np.zeros((n_test)) # randomness for player 2\n",
    "        s = game.play_games([], r1, P, r2, n_test, nargout = 1)\n",
    "        print(\" net plays white: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "            (s[0][1],s[0][0],s[0][2]))\n",
    "\n",
    "    print(\"Evaluating generation %d neural network against itself\" % generation)\n",
    "\n",
    "    r1 = np.zeros((n_test)) # randomness for player 1\n",
    "    r2 = np.zeros((n_test))  # randomness for player 2\n",
    "    s = game.play_games(P, r1, P, r2, n_test, nargout = 1)\n",
    "    print(\"win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "        (s[0][0],s[0][1],s[0][2]))\n",
    "    print(\"\\n-----------------------------------\\n\")\n",
    "    print(\"Evaluating generation %d neural network on all games\" % generation)\n",
    "\n",
    "    r1 = np.zeros((n_test)) # randomness for player 1\n",
    "    r2 = np.ones((n_test))  # randomness for player 2\n",
    "    s = game.play_games_all(P, r1, [], r2, 1, nargout = 1)\n",
    "    win1.append(s[0][0]); lose1.append(s[0][1]); tie1.append(s[0][2]);\n",
    "    print(\" net plays black: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "         (s[0][0],s[0][1],s[0][2]))  \n",
    "\n",
    "    r1 = np.ones((n_test))  # randomness for player 1\n",
    "    r2 = np.zeros((n_test)) # randomness for player 2\n",
    "    s = game.play_games_all([], r1, P, r2, 1, nargout = 1)\n",
    "    win2.append(s[0][1]); lose2.append(s[0][0]); tie2.append(s[0][2]);\n",
    "    print(\" net plays white: win=%6.6f, loss=%6.6f, tie=%6.6f\" %\\\n",
    "                  (s[0][1],s[0][0],s[0][2]))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on the network performance\n",
    "The network was trained during 5 generations, where for each generation the amount of random actions was shrinked proportionally: \n",
    "    \n",
    "    * during the first generation the network is trained on random plays\n",
    "    * the second is trained based on game records played by the first neural network\n",
    "    * etc\n",
    "    \n",
    "From the results above can be seen that fully trained network never looses against the random policy.\n",
    "Also based on all games, network always shows the winning strategy or tie:\n",
    "\n",
    "    * for the black random player number of valid games is 2373 because lots of the games \n",
    "    repeat (e.g. board1: 134 and board2: 135 may end up in the same board like 1345, \n",
    "    which happens due to the agent moves as well as breadth-first search)\n",
    "    * for the white random player number of valid games is 688\n",
    "    \n",
    "And against itself the network shows the tie, hence our player is the most optimal, because it never looses and shows a tie in case it plays with another optimal player."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
